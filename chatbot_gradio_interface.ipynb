{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6479db49f9b84d14952cab4623bdc3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bb0235ae2848bc99b0d5692d95422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d0ea0f43f14c9ab9b1b1fba8045923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load your model\n",
    "model_name = \"medachbab/phi2-sql-v3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL generation function\n",
    "'''def generate_sql(context, question):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Generate SQL query based on the following context and question.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\")[-1].strip()'''\n",
    "def generate_sql(context, question):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Generate SQL query based on the following context and question.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://d9cb1ce8272597c6d0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d9cb1ce8272597c6d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "tables = []\n",
    "\n",
    "def save_table(name, n1, n2, n3, n4, n5, t1, t2, t3, t4, t5):\n",
    "    if not name.strip():\n",
    "        return \"‚ùå Table name is required.\"\n",
    "\n",
    "    cols = []\n",
    "    for n, t in zip([n1, n2, n3, n4, n5], [t1, t2, t3, t4, t5]):\n",
    "        if n.strip() and t:\n",
    "            cols.append({\"name\": n.strip(), \"type\": t})\n",
    "\n",
    "    if not cols:\n",
    "        return \"‚ùå Add at least one valid column.\"\n",
    "\n",
    "    tables.append({\n",
    "        \"name\": name.strip(),\n",
    "        \"columns\": cols\n",
    "    })\n",
    "\n",
    "    return f\"‚úÖ Table '{name}' saved with {len(cols)} columns.\"\n",
    "\n",
    "def generate_sql_context():\n",
    "    if not tables:\n",
    "        return \"‚ö†Ô∏è No tables defined.\"\n",
    "\n",
    "    stmts = []\n",
    "    for table in tables:\n",
    "        name = table[\"name\"]\n",
    "        cols = [f\"{col['name']} {col['type']}\" for col in table[\"columns\"]]\n",
    "        stmts.append(f\"CREATE TABLE {name} (\\n  \" + \",\\n  \".join(cols) + \"\\n);\")\n",
    "\n",
    "    return \"\\n\\n\".join(stmts)\n",
    "\n",
    "def generate_sql(context, question):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Generate SQL query based on the following context and question.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\")[-1].strip()\n",
    "\n",
    "def clear_all():\n",
    "    tables.clear()\n",
    "    return \"\", \"\", \"\", \"\", \"\", \"\", None, None, None, None, None, \"\", \"\", \"\"\n",
    "\n",
    "with gr.Blocks(theme=\"default\") as app:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üß† SQL Table & Query Generator\n",
    "    Easily define SQL tables, generate schemas, and ask questions to get SQL queries.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Accordion(\"üìã Define Table Schema\", open=True):\n",
    "        with gr.Row():\n",
    "            table_name = gr.Textbox(label=\"Table Name\", placeholder=\"e.g. users\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name1 = gr.Textbox(label=\"Column 1 Name\")\n",
    "            col_type1 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name2 = gr.Textbox(label=\"Column 2 Name\")\n",
    "            col_type2 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name3 = gr.Textbox(label=\"Column 3 Name\")\n",
    "            col_type3 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name4 = gr.Textbox(label=\"Column 4 Name (optional)\")\n",
    "            col_type4 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name5 = gr.Textbox(label=\"Column 5 Name (optional)\")\n",
    "            col_type5 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            save_btn = gr.Button(\"üíæ Save Table\", variant=\"primary\")\n",
    "            clear_btn = gr.Button(\"üßπ Clear All\", variant=\"secondary\")\n",
    "        status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    with gr.Accordion(\"üõ†Ô∏è Generate SQL Schema\", open=True):\n",
    "        generate_sql_btn = gr.Button(\"‚öôÔ∏è Generate SQL Context\", variant=\"secondary\")\n",
    "        context_output = gr.Code(label=\"SQL Context\", language=\"sql\", interactive=False)\n",
    "\n",
    "    with gr.Accordion(\"üîé Ask SQL Question\", open=True):\n",
    "        question_input = gr.Textbox(label=\"Question\", placeholder=\"e.g. Show all users older than 30\", lines=2)\n",
    "        ask_sql_btn = gr.Button(\"üöÄ Generate SQL Query\", variant=\"primary\")\n",
    "        final_sql_output = gr.Code(label=\"Generated SQL\", language=\"sql\", interactive=False)\n",
    "\n",
    "    save_btn.click(\n",
    "        save_table,\n",
    "        inputs=[table_name, col_name1, col_name2, col_name3, col_name4, col_name5,\n",
    "                col_type1, col_type2, col_type3, col_type4, col_type5],\n",
    "        outputs=[status]\n",
    "    )\n",
    "\n",
    "    generate_sql_btn.click(\n",
    "        generate_sql_context,\n",
    "        outputs=[context_output]\n",
    "    )\n",
    "\n",
    "    ask_sql_btn.click(\n",
    "        generate_sql,\n",
    "        inputs=[context_output, question_input],\n",
    "        outputs=[final_sql_output]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        clear_all,\n",
    "        outputs=[\n",
    "            table_name, col_name1, col_name2, col_name3, col_name4, col_name5,\n",
    "            col_type1, col_type2, col_type3, col_type4, col_type5,\n",
    "            status, context_output, final_sql_output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://2d23c1807c4584ea33.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2d23c1807c4584ea33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# State to hold multiple tables\n",
    "tables = []\n",
    "\n",
    "# Function to save the table from user inputs\n",
    "def save_table(name, n1, n2, n3, t1, t2, t3):\n",
    "    if not name.strip():\n",
    "        return \"‚ùå Table name is required.\"\n",
    "\n",
    "    cols = []\n",
    "    for n, t in zip([n1, n2, n3], [t1, t2, t3]):\n",
    "        if n.strip() and t:\n",
    "            cols.append({\"name\": n.strip(), \"type\": t})\n",
    "\n",
    "    if not cols:\n",
    "        return \"‚ùå Add at least one valid column.\"\n",
    "\n",
    "    tables.append({\n",
    "        \"name\": name.strip(),\n",
    "        \"columns\": cols\n",
    "    })\n",
    "\n",
    "    return f\"‚úÖ Table '{name}' saved with {len(cols)} columns.\"\n",
    "\n",
    "# Function to generate the CREATE TABLE SQL statements from saved tables\n",
    "def generate_sql_context():\n",
    "    if not tables:\n",
    "        return \"‚ö†Ô∏è No tables defined.\"\n",
    "\n",
    "    stmts = []\n",
    "    for table in tables:\n",
    "        name = table[\"name\"]\n",
    "        cols = [f\"{col['name']} {col['type']}\" for col in table[\"columns\"]]\n",
    "        stmts.append(f\"CREATE TABLE {name} (\\n  \" + \",\\n  \".join(cols) + \"\\n);\")\n",
    "\n",
    "    return \"\\n\\n\".join(stmts)\n",
    "\n",
    "# Function to call the language model and generate SQL\n",
    "def generate_sql(context, question):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Generate SQL query based on the following context and question.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\")[-1].strip()\n",
    "\n",
    "# Function to clear everything\n",
    "def clear_all():\n",
    "    tables.clear()  # reset global state\n",
    "    return \"\", \"\", \"\", \"\", None, None, None, \"\", \"\", \"\"\n",
    "\n",
    "# Build the Gradio UI\n",
    "with gr.Blocks(theme=\"default\") as app:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üß† SQL Table & Query Generator\n",
    "    Easily define SQL tables, generate schemas, and ask questions to get SQL queries.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Accordion(\"üìã Define Table Schema\", open=True):\n",
    "        with gr.Row():\n",
    "            table_name = gr.Textbox(label=\"Table Name\", placeholder=\"e.g. users\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name1 = gr.Textbox(label=\"Column 1 Name\")\n",
    "            col_type1 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name2 = gr.Textbox(label=\"Column 2 Name\")\n",
    "            col_type2 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            col_name3 = gr.Textbox(label=\"Column 3 Name\")\n",
    "            col_type3 = gr.Dropdown([\"INT\", \"VARCHAR\", \"TEXT\", \"DATE\", \"BOOLEAN\", \"FLOAT\"], label=\"Type\")\n",
    "\n",
    "        with gr.Row():\n",
    "            save_btn = gr.Button(\"üíæ Save Table\", variant=\"primary\")\n",
    "            clear_btn = gr.Button(\"üßπ Clear All\", variant=\"secondary\")\n",
    "        status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    with gr.Accordion(\"üõ†Ô∏è Generate SQL Schema\", open=True):\n",
    "        generate_sql_btn = gr.Button(\"‚öôÔ∏è Generate SQL Context\", variant=\"secondary\")\n",
    "        context_output = gr.Code(label=\"SQL Context\", language=\"sql\", interactive=False)\n",
    "\n",
    "    with gr.Accordion(\"üîé Ask SQL Question\", open=True):\n",
    "        question_input = gr.Textbox(label=\"Question\", placeholder=\"e.g. Show all users older than 30\", lines=2)\n",
    "        ask_sql_btn = gr.Button(\"üöÄ Generate SQL Query\", variant=\"primary\")\n",
    "        final_sql_output = gr.Code(label=\"Generated SQL\", language=\"sql\", interactive=False)\n",
    "\n",
    "    # Event bindings\n",
    "    save_btn.click(\n",
    "        save_table,\n",
    "        inputs=[table_name, col_name1, col_name2, col_name3, col_type1, col_type2, col_type3],\n",
    "        outputs=[status]\n",
    "    )\n",
    "\n",
    "    generate_sql_btn.click(\n",
    "        generate_sql_context,\n",
    "        outputs=[context_output]\n",
    "    )\n",
    "\n",
    "    ask_sql_btn.click(\n",
    "        generate_sql,\n",
    "        inputs=[context_output, question_input],\n",
    "        outputs=[final_sql_output]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        clear_all,\n",
    "        outputs=[\n",
    "            table_name, col_name1, col_name2, col_name3,\n",
    "            col_type1, col_type2, col_type3,\n",
    "            status, context_output, final_sql_output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
